{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87d94c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT PACKAGE\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "#from tensorflow.keras.utils import img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeba4537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAKE TRAIN AND VALIDATION DIRECTORY\n",
    "\n",
    "#DON'T FORGET TO CHANGE THE DIRECTORY PATH\n",
    "train_dir = \"C:/Users/ACER/Documents/UNDIP/Dataset Tembakau resize/Training/\"\n",
    "train_rendah_dir = os.path.join(train_dir, \"Rendah/\")\n",
    "train_sedang_dir = os.path.join(train_dir, \"Sedang/\")\n",
    "train_tinggi_dir = os.path.join(train_dir, \"Tinggi/\")\n",
    "\n",
    "#DON'T FORGET TO CHANGE THE DIRECTORY PATH\n",
    "validation_dir = \"C:/Users/ACER/Documents/UNDIP/Dataset Tembakau resize/Validation/\"\n",
    "validation_rendah_dir = os.path.join(validation_dir, \"Rendah/\")\n",
    "validation_sedang_dir = os.path.join(validation_dir, \"Sedang/\")\n",
    "validation_tinggi_dir = os.path.join(validation_dir, \"Tinggi/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e36128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHOW TRAIN IMAGE\n",
    "\n",
    "print(\"Sample rendah image:\")\n",
    "plt.imshow(load_img(f\"{os.path.join(train_rendah_dir, os.listdir(train_rendah_dir)[0])}\"))\n",
    "plt.show()\n",
    "\n",
    "print(\"Sample sedang image:\")\n",
    "plt.imshow(load_img(f\"{os.path.join(train_sedang_dir, os.listdir(train_sedang_dir)[0])}\"))\n",
    "plt.show()\n",
    "\n",
    "print(\"Sample tinggi image:\")\n",
    "plt.imshow(load_img(f\"{os.path.join(train_tinggi_dir, os.listdir(train_tinggi_dir)[0])}\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b808389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first example of a Garangan Tobacco low class\n",
    "sample_image  = load_img(f\"{os.path.join(train_rendah_dir, os.listdir(train_rendah_dir)[0])}\")\n",
    "\n",
    "# Convert the image into its numpy array representation\n",
    "sample_array = img_to_array(sample_image)\n",
    "\n",
    "print(f\"Each image has shape: {sample_array.shape}\")\n",
    "\n",
    "print(f\"The maximum pixel value used is: {np.max(sample_array)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a6159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator(train_dir,validation_dir):\n",
    "    # Instantiate the ImageDataGenerator class.\n",
    "    # Remember to set the rescale argument.\n",
    "    train_datagen = ImageDataGenerator(rescale=1/255,\n",
    "                                     rotation_range=40,\n",
    "                                     width_shift_range=0.2,\n",
    "                                     height_shift_range=0.2,\n",
    "                                     shear_range=0.2,\n",
    "                                     zoom_range=0.2,\n",
    "                                     horizontal_flip=True,\n",
    "                                     fill_mode=\"nearest\")\n",
    "\n",
    "    # Specify the method to load images from a directory and pass in the appropriate arguments:\n",
    "    # - directory: should be a relative path to the directory containing the data\n",
    "    # - targe_size: set this equal to the resolution of each image (excluding the color dimension)\n",
    "    # - batch_size: number of images the generator yields when asked for a next batch. Set this to 10.\n",
    "    # - class_mode: How the labels are represented. Should be one of \"binary\", \"categorical\" or \"sparse\".\n",
    "    #               Pick the one that better suits here given that the labels are going to be 1D binary labels.\n",
    "    train_generator = train_datagen.flow_from_directory(directory=train_dir,\n",
    "                                                        target_size=(224, 224),\n",
    "                                                        batch_size=16,\n",
    "                                                        class_mode=\"categorical\")\n",
    "    \n",
    "    # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
    "    # Remember that validation data should not be augmented\n",
    "    validation_datagen = ImageDataGenerator( rescale = 1/255 )\n",
    "\n",
    "    # Pass in the appropriate arguments to the flow_from_directory method\n",
    "    validation_generator = validation_datagen.flow_from_directory(directory=validation_dir,\n",
    "                                                                 batch_size=16, \n",
    "                                                                 class_mode='categorical',\n",
    "                                                                 target_size=(224, 224))\n",
    "    ### END CODE HERE\n",
    "\n",
    "    return train_generator,validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b44660",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, validation_generator = image_generator(train_dir, validation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad55604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the inception model  \n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "\n",
    "# Load the MobileNet model\n",
    "pre_trained_model = MobileNet(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "# Create an instance of the inception model from the local pre-trained weights\n",
    "#DON'T FORGET TO CHANGE THE DIRECTORY PATH\n",
    "#local_weights_file = 'C:/Users/ACER/Downloads/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12217c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_pre_trained_model\n",
    "\n",
    "'''def create_pre_trained_model(local_weights_file):\n",
    "  \"\"\"\n",
    "  Initializes an InceptionV3 model.\n",
    "  \n",
    "  Args:\n",
    "    local_weights_file (string): path pointing to a pretrained weights H5 file\n",
    "    \n",
    "  Returns:\n",
    "    pre_trained_model: the initialized InceptionV3 model\n",
    "  \"\"\"\n",
    "  ### START CODE HERE\n",
    "  pre_trained_model = InceptionV3(input_shape = (300, 300, 3),\n",
    "                                  include_top = False, \n",
    "                                  weights = None) \n",
    "\n",
    "  pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "  # Make all the layers in the pre-trained model non-trainable\n",
    "  for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "  ### END CODE HERE\n",
    "\n",
    "  return pre_trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5db4c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre_trained_model = create_pre_trained_model(local_weights_file)\n",
    "\n",
    "# Print the model summary\n",
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a858304",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = pre_trained_model.count_params()\n",
    "num_trainable_params = sum([w.shape.num_elements() for w in pre_trained_model.trainable_weights])\n",
    "\n",
    "print(f\"There are {total_params:,} total parameters in this model.\")\n",
    "print(f\"There are {num_trainable_params:,} trainable parameters in this model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c257fc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('accuracy')>0.999):\n",
    "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6efa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_of_last_layer\n",
    "\n",
    "def output_of_last_layer(pre_trained_model):\n",
    "  \"\"\"\n",
    "  Gets the last layer output of a model\n",
    "  \n",
    "  Args:\n",
    "    pre_trained_model (tf.keras Model): model to get the last layer output from\n",
    "    \n",
    "  Returns:\n",
    "    last_output: output of the model's last layer \n",
    "  \"\"\"\n",
    "  ### START CODE HERE\n",
    "  last_desired_layer = pre_trained_model.get_layer('conv_pw_13_relu')\n",
    "  print('last layer output shape: ', last_desired_layer.output_shape)\n",
    "  last_output = last_desired_layer.output\n",
    "  print('last layer output: ', last_output)\n",
    "  ### END CODE HERE\n",
    "\n",
    "  return last_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7b730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_output = output_of_last_layer(pre_trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324f970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the type of the pre-trained model\n",
    "print(f\"The pretrained model has type: {type(pre_trained_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a7afc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_uncompiled_model():\n",
    "\n",
    "    ### START CODE HERE\n",
    "    \n",
    "    # Flatten the output layer to 1 dimension\n",
    "    x = layers.Flatten()(last_output)\n",
    "\n",
    "    ### START CODE HERE\n",
    "\n",
    "    # Add a fully connected layer with 1024 hidden units and ReLU activation\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    # Add a dropout rate of 0.2\n",
    "    x = layers.Dropout(0.2)(x)       \n",
    "    # Add a final sigmoid layer for classification\n",
    "    x = x = layers.Dense(3, activation='softmax')(x)         \n",
    "\n",
    "    # Create the complete model by using the Model class\n",
    "    model = Model(inputs=pre_trained_model.input, outputs=x)\n",
    "    \n",
    "    ### END CODE HERE\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3442e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your uncompiled model\n",
    "uncompiled_model = create_uncompiled_model()\n",
    "\n",
    "try:\n",
    "    uncompiled_model.predict(train_generator)\n",
    "except:\n",
    "    print(\"Your current architecture is incompatible with the windowed dataset, try adjusting it.\")\n",
    "else:\n",
    "    print(\"Your current architecture is compatible with the windowed dataset! :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5ebcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(dataset):\n",
    "    \n",
    "    model = create_uncompiled_model()\n",
    "    \n",
    "    lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch / 20))\n",
    "    \n",
    "    ### START CODE HERE\n",
    "    \n",
    "    # Select your optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    \n",
    "    # Compile the model passing in the appropriate loss\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[\"accuracy\"]) \n",
    "    \n",
    "    ### END CODE HERE\n",
    "    \n",
    "    history = model.fit(train_generator, epochs=20, callbacks=[lr_schedule])\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bf7daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training with dynamic LR\n",
    "lr_history = adjust_learning_rate(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47809290",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(lr_history.history[\"lr\"], lr_history.history[\"loss\"])\n",
    "plt.axis([1e-4, 10, 0, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e9df6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_final_model\n",
    "\n",
    "def create_final_model(pre_trained_model, last_output):\n",
    "  \"\"\"\n",
    "  Appends a custom model to a pre-trained model\n",
    "  \n",
    "  Args:\n",
    "    pre_trained_model (tf.keras Model): model that will accept the train/test inputs\n",
    "    last_output (tensor): last layer output of the pre-trained model\n",
    "    \n",
    "  Returns:\n",
    "    model: the combined model\n",
    "  \"\"\"\n",
    "  # SAMAKAN MODEL FINAL DENGAN MODEL UNCOMPILED\n",
    "  # Flatten the output layer to 1 dimension\n",
    "  x = layers.Flatten()(last_output)\n",
    "\n",
    "  ### START CODE HERE\n",
    "\n",
    "  # Add a fully connected layer with 1024 hidden units and ReLU activation\n",
    "  x = layers.Dense(128, activation='relu')(x)\n",
    "  # Add a dropout rate\n",
    "  x = layers.Dropout(0.2)(x)       \n",
    "  # Add a final sigmoid layer for classification\n",
    "  x = x = layers.Dense(3, activation='softmax')(x)         \n",
    "\n",
    "  # Create the complete model by using the Model class\n",
    "  model = Model(inputs=pre_trained_model.input, outputs=x)\n",
    "\n",
    "  # Compile the model\n",
    "  model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "                loss = 'categorical_crossentropy',\n",
    "                metrics = ['accuracy'])\n",
    "\n",
    "  ### END CODE HERE\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5919bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your model in a variable\n",
    "model = create_final_model(pre_trained_model, last_output)\n",
    "\n",
    "# Inspect parameters\n",
    "total_params = model.count_params()\n",
    "num_trainable_params = sum([w.shape.num_elements() for w in model.trainable_weights])\n",
    "\n",
    "print(f\"There are {total_params:,} total parameters in this model.\")\n",
    "print(f\"There are {num_trainable_params:,} trainable parameters in this model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d55896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = myCallback()\n",
    "history = model.fit(train_generator,\n",
    "                    validation_data = validation_generator,\n",
    "                    epochs = 100,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321c7da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./C:/Users/ACER/Project Bangkit/model.pb')\n",
    "model.save('./C:/Users/ACER/Project Bangkit/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce24b963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE: Use the tf.saved_model API to save your model in the SavedModel format. \n",
    "export_dir = './C:/Users/ACER/Project Bangkit/'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "tf.saved_model.save(model,export_dir=export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc224f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./C:/Users/ACER/Project Bangkit/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4a2d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = tf.keras.models.load_model('./C:/Users/ACER/Project Bangkit/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a86f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE: Use the TFLiteConverter SavedModel API to initialize the converter\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(my_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e57485",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model_file = pathlib.Path('./model.tflite')\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6109ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "open('./Mbako/MyDrive/Mbako/SaveModel/Model.tflite','wb').write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
